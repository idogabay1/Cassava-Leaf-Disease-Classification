{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava Leaf Disease Classification on balanced test-set",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1t21RzzRRWo"
      },
      "source": [
        "###################### READ ME #######################\n",
        "#This project solve the classification of Cassava leaf diseases from biased train-set to balanced test-set.\n",
        "#The dataset is based on the ‚ÄúCassava Leaf Disease Classification‚Äù dataset from Kaggle.\n",
        "#You can find it here : https://www.kaggle.com/c/cassava-leaf-disease-classification\n",
        "####NOTE that for some application we extended this dataset. If you wish to use the extended dataset you can do so using the script we provide in this documentation.\n",
        "#We used Google Colab for running our code so all of it designed for it.\n",
        "#Enjoy üòä\n",
        "#####################################################"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFmdgEwSRNC5"
      },
      "source": [
        "### This line solves compatibility issues with processing the linear layers. It take some times but necessary.\n",
        "\n",
        "pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guibB2d_W2mC"
      },
      "source": [
        "### Installing Optuna. This is not necessary if you do not intend to use Optuna for building a new architecture and only use the provided architectures.\n",
        "\n",
        "pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSDu8ZEpWhl9"
      },
      "source": [
        "### Python imports\n",
        "# imports for the practice (you can add more if you need)\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.data.sampler import SubsetRandomSampler as sub_rand_sampler\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "# %matplotlib notebook\n",
        "%matplotlib inline\n",
        "### random seed for later.\n",
        "seed = 70\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NwYygTDZn1HM",
        "outputId": "c1dd2c92-8060-4edf-bb62-48693c6c6b59"
      },
      "source": [
        "### Generating the extended dataset.\n",
        "### We did it one time locally to our computer and with this data generated the zip file.\n",
        "### To use this script make a copy of the data because it‚Äôs going to delete the renamed files.\n",
        "\n",
        "pic_name = []\n",
        "pic_label = []\n",
        "original_pic_name = []\n",
        "f1 = open(\"./dataset-train-not-class3.csv\",'r') ###csv without class 3 samples.\n",
        "reader = csv.reader(f1)\n",
        "for row in reader:\n",
        "    original_pic_name.append(row[0])\n",
        "    pic_name.append(row[0]+'_copy1.jpg')\n",
        "    pic_label.append(row[1])\n",
        "\n",
        "f2 = open(\"./non3_copy_1.csv\",'r+')\n",
        "writer = csv.writer(f2)\n",
        "for i in range(len(pic_name)):\n",
        "    writer.writerow([pic_name[i],pic_label[i]])\n",
        "\n",
        "for count, filename in enumerate(os.listdir(\"800_600_full\")):\n",
        "    \n",
        "    if filename in original_pic_name:\n",
        "        src =\"dataset/\"+filename\n",
        "        dst =\"dataset_extension1/\"+filename+'_copy1.jpg'\n",
        "        os.rename(src, dst)\n",
        "\n",
        "f1.close\n",
        "f2.close\n",
        "\n",
        "### We executed this script 3 times, each time with different extension number (change 1,2 and 3 in all the places)."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-311ec831d9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpic_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moriginal_pic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dataset-train-not-class3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset-train-not-class3.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbch0PBYRSt"
      },
      "source": [
        "### Configure the computation device \n",
        "\n",
        "# check if there is a GPU available\n",
        "print(torch.cuda.is_available())\n",
        "# check what is the current available device\n",
        "if torch.cuda.is_available():\n",
        "    print(\"current device: \", torch.cuda.current_device())\n",
        "# automatically choose device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # use gpu 0 if it is available, o.w. use the cpu\n",
        "print(\"device: \", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9p9y3IhZMqR"
      },
      "source": [
        "### Mount your Google Drive in Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odcTbJsxaULC"
      },
      "source": [
        "### Imports the dataset from  Google Drive. We found it the most efficient way to transfer the data to Google Colab many times.\n",
        "###To do so, save the dataset as a zip file in the name ‚Äúdataset.zip‚Äù in Google Drive.\n",
        "\n",
        "! mkdir \"dataset\" #create a new folder\n",
        "!cp \"/content/drive/MyDrive/YOUR_PATH/dataset.zip\" \"/content/dataset\" #copy the zip file\n",
        "! unzip '/content/dataset/dataset.zip' -d \"/content/dataset\" #unzip\n",
        "\n",
        "###Note that we included in our zip file the extended dataset. This is not necessary "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvjFO1MagoLT"
      },
      "source": [
        "image_path = \"/content/dataset\" #dataset images path\n",
        "\n",
        "\n",
        "### This comment contain several csv paths including the extensions.\n",
        "###We do so to make several datasets for implying different augmentations on each extension.\n",
        "###Use it only if you extended the data.\n",
        "\"\"\"\n",
        "train_csv_without_class3 = \"/content/drive/MyDrive/CSV_PATH/dataset-train-not-class3.csv\"\n",
        "train_csv_without_class3_copy1 = \"/content/drive/MyDrive/CSV_PATH/dataset_train_non3_extension_1.csv\"\n",
        "train_csv_without_class3_copy2 = \"/content/drive/MyDrive/CSV_PATH/dataset_train_non3_extension_2.csv\"\n",
        "train_csv_without_class3_copy3 = \"/content/drive/MyDrive//dataset_train_non3_extension_3.csv\"\n",
        "train_csv_only_class3 = \"/content/drive/MyDrive/deep_final_project/csv/dataset-train-only-class3.csv\"\n",
        "test_csv_path = \"/content/drive/MyDrive/deep_final_project/csv/dataset-test.csv\"\n",
        "\"\"\"\n",
        "\n",
        "### Note that use use imbalanced train-set and balanced test-set.\n",
        "train_csv = \"/content/drive/MyDrive/CSV_PATH/dataset-train.csv\"\n",
        "test_csv_path = \"/content/drive/MyDrive/CSV_PATH/dataset-mini-test.csv\"\n",
        "\n",
        "### Show the begining of the CSV \n",
        "csv_file = pd.read_csv(train_csv)\n",
        "csv_file.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHI09ImilXTU"
      },
      "source": [
        "### Dataset class\n",
        "\n",
        "class Cassava_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, image_path,csv_file, Transform=None):\n",
        "        self.image_path = image_path\n",
        "        self.csv = pd.read_csv(csv_file) \n",
        "        self.transform = Transform\n",
        "        \n",
        "    def __len__(self): \n",
        "      return len(self.csv)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "      if torch.is_tensor(idx):\n",
        "        idx = idx.tolist()\n",
        "       \n",
        "      image = Image.open(os.path.join(self.image_path, self.csv.iloc[idx,0]))\n",
        "      label = self.csv.iloc[idx,1]\n",
        "        #if self.image_path == '../input/cassava-leaf-disease-classification/train_images':\n",
        "      return self.transform(image), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt4bBG_MnPkD"
      },
      "source": [
        "### augmentation setup.\n",
        "### You can choose the transform you want. The basic one only normalize the data and turn it in to tensor.\n",
        "\n",
        "basic_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])#transforms.Resize((200,150)),\n",
        "\n",
        "transform1 = transforms.Compose([transforms.Resize((224,224)),transforms.RandomRotation((7,15)),\n",
        "                                 torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=1),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "transform1_point_5 = transforms.Compose([transforms.Resize((224,224)),transforms.RandomRotation((7,15)),\n",
        "                                 torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=1),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "transform2 = transforms.Compose([transforms.Resize((224,224)),torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=1),\n",
        "                                 transforms.RandomRotation((-15,-7)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "transform3 = transforms.Compose([transforms.Resize((224,224)),torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=1),\n",
        "                                 transforms.RandomRotation((7,15)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
        "\n",
        "transform4 = transforms.Compose([transforms.Resize((224,224)),torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=1),\n",
        "                                 transforms.RandomRotation((12,17)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
        "\n",
        "crop_transform = transforms.Compose([transforms.Resize((224,224)),torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.8, p=0.5),\n",
        "                                     torchvision.transforms.RandomAdjustSharpness(sharpness_factor=1.2, p=0.5),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n",
        "                                     torchvision.transforms.RandomCrop((180,180)),#, padding=48, fill=0, padding_mode='constant')])\n",
        "                                     torchvision.transforms.Pad(22, fill=0, padding_mode='constant')])\n",
        "\n",
        "transform_resnet_basic = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "\n",
        "class_3_transform = basic_transform\n",
        "train_transform = basic_transform\n",
        "test_transform = basic_transform\n",
        "\n",
        "\n",
        "### Note that the commented part is for the extended data.\n",
        "\"\"\"\n",
        "train_without_class3_dataset1 = Cassava_Dataset(image_path,train_csv_without_class3,all_trandform)\n",
        "train_only_3_class_dataset = Cassava_Dataset(image_path,train_csv_only_class3,all_trandform)\n",
        "\n",
        "train_without_class3_dataset2 = Cassava_Dataset(image_path,train_csv_without_class3_copy1,all_trandform)\n",
        "train_without_class3_dataset3 = Cassava_Dataset(image_path,train_csv_without_class3_copy2,all_trandform)\n",
        "train_without_class3_dataset4 = Cassava_Dataset(image_path,train_csv_without_class3_copy3,all_trandform)\n",
        "\n",
        "\n",
        "train_dataset = torch.utils.data.ConcatDataset((train_without_class3_dataset4,train_without_class3_dataset1,\n",
        "                                                train_only_3_class_dataset, train_without_class3_dataset2,\n",
        "                                                train_without_class3_dataset3))\n",
        "\"\"\"\n",
        "\n",
        "##for optuna\n",
        "train_dataset = Cassava_Dataset(image_path,train_csv,train_transform)\n",
        "\n",
        "\n",
        "\n",
        "test_dataset = Cassava_Dataset(image_path,test_csv_path,test_transform)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "### split the test to validation and test\n",
        "val_len = int(len(test_dataset)*0.5)\n",
        "test_len = len(test_dataset) - val_len\n",
        "test_set, valid_set = random_split(test_dataset, [test_len, val_len])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set,batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct5oQfjxtJ-u"
      },
      "source": [
        "############## Network Selection ##################\n",
        "### In this project we tried several architectures.\n",
        "### in the following sections YOU NEED TO CHOOSE ONLY ONE and change the model name in the right place afterward."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHt6KsnT0DH_"
      },
      "source": [
        "### fork of cassva model. copied from : \"https://www.kaggle.com/charlesrongione/fork-of-cassava\"\n",
        "\n",
        "class Fork_of_cassava(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "        \n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,padding=1)\n",
        "    self.fc1 = nn.Linear(180000, 512)\n",
        "    self.fc2 = nn.Linear(512, 5)       \n",
        "  \n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = nn.functional.relu(self.conv1(x))\n",
        "    x = torch.flatten(nn.functional.max_pool2d(nn.functional.relu(self.conv2(x)),2),1)\n",
        "    x = self.fc1(x)\n",
        "    x = nn.functional.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3nWHmTp0EXB"
      },
      "source": [
        "### Our attempt to improve cassava model using Batch norm, dropout, pooling, and STN layer.\n",
        "### You can find more information on STN here : \" https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html‚Äù\n",
        "\n",
        "class Fork_of_cassava_improved_with_stn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Fork_of_cassava_improved_with_stn, self).__init__()\n",
        "    \n",
        "    ##STN block\n",
        "    self.localization = nn.Sequential(nn.Conv2d(3, 8, kernel_size=7),\n",
        "            nn.MaxPool2d(2, stride=2),nn.ReLU(True),nn.Conv2d(8, 10, kernel_size=5),\n",
        "            nn.MaxPool2d(2, stride=2),nn.ReLU(True))   \n",
        "    # Regressor for the 3 * 2 affine matrix\n",
        "    self.fc_loc = nn.Sequential(nn.Linear ( 2001920, 32),nn.ReLU(True),\n",
        "        nn.Linear(32, 3 * 2))\n",
        "\n",
        "    self.fc_loc[2].weight.data.zero_()\n",
        "    self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))         \n",
        "    ##end of stn block\n",
        "\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
        "    self.baNorm1 = nn.BatchNorm2d(32)\n",
        "    self.max_pool1 = nn.MaxPool2d((2,2))\n",
        "    self.drop1 = nn.Dropout(0.1)\n",
        "    \n",
        "    self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
        "    self.baNorm2 = nn.BatchNorm2d(64)\n",
        "    self.max_pool2 = nn.MaxPool2d((2,2))\n",
        "    self.drop2 = nn.Dropout(0.1)\n",
        "\n",
        "    self.fc1 = nn.Linear(110592, 216)\n",
        "    self.BaNorm5=nn.BatchNorm1d(216)\n",
        "    self.drop5=nn.Dropout(0.1)\n",
        "    \n",
        "    self.fc2 = nn.Linear(216, 5)  \n",
        "\n",
        "  def stn(self, x):\n",
        "    xs = self.localization(x)\n",
        "    xs = xs.view(-1, 2001920)\n",
        "    theta = self.fc_loc(xs)\n",
        "    theta = theta.view(-1, 2, 3)\n",
        "    print('bi')\n",
        "    grid = F.affine_grid(theta, x.size())\n",
        "    print('sha')\n",
        "    x = F.grid_sample(x, grid)\n",
        "    print('va')\n",
        "    return x\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.stn(x)\n",
        "    x = self.max_pool1(nn.functional.relu(self.baNorm1(self.conv1(x))))\n",
        "    x = self.drop1(x)\n",
        "\n",
        "    x = self.max_pool2(nn.functional.relu(self.baNorm2(self.conv2(x))))\n",
        "    x = self.drop2(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.drop5(torch.relu(self.BaNorm5(self.fc1(x))))\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eNhQQQjw9U9"
      },
      "source": [
        "### Optuna model suggestion number 2\n",
        "\n",
        "class optuna_res_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"CNN Builder.\"\"\"\n",
        "    super(optuna_res_2, self).__init__()\n",
        "    #the network\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=92,kernel_size=3,padding=1)\n",
        "    self.baNorm1 = nn.BatchNorm2d(92)\n",
        "    self.drop1 = nn.Dropout(0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=92,out_channels=76,kernel_size=3,padding=1)\n",
        "    self.baNorm2 = nn.BatchNorm2d(76)\n",
        "    self.drop2 = nn.Dropout(0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=76,out_channels=78,kernel_size=3,padding=1)\n",
        "    self.baNorm3 = nn.BatchNorm2d(78)\n",
        "    self.drop3 = nn.Dropout(0)\n",
        "    \n",
        "    self.conv4 = nn.Conv2d(in_channels=78,out_channels=44,kernel_size=3,padding=1)\n",
        "    self.baNorm4 = nn.BatchNorm2d(44)\n",
        "    self.drop4 = nn.Dropout(0)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels=44,out_channels=71,kernel_size=3,padding=1)\n",
        "    self.baNorm5 = nn.BatchNorm2d(71)\n",
        "    self.drop5 = nn.Dropout(0)\n",
        "\n",
        "    self.conv6 = nn.Conv2d(in_channels=71,out_channels=120,kernel_size=3,padding=1)\n",
        "    self.baNorm6 = nn.BatchNorm2d(120)\n",
        "    self.drop6 = nn.Dropout(0)\n",
        "\n",
        "    self.conv7 = nn.Conv2d(in_channels=120,out_channels=27,kernel_size=3,padding=1)\n",
        "    self.baNorm7 = nn.BatchNorm2d(27)\n",
        "    self.drop7 = nn.Dropout(0)\n",
        "\n",
        "    self.conv8 = nn.Conv2d(in_channels=27,out_channels=104,kernel_size=3,padding=1)\n",
        "    self.baNorm8 = nn.BatchNorm2d(104)\n",
        "    self.drop8 = nn.Dropout(0)\n",
        "\n",
        "    self.conv9 = nn.Conv2d(in_channels=104,out_channels=66,kernel_size=3,padding=1)\n",
        "    self.baNorm9 = nn.BatchNorm2d(66)\n",
        "    self.drop9 = nn.Dropout(0)\n",
        "    \n",
        "    self.conv10 = nn.Conv2d(in_channels=66,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm10 = nn.BatchNorm2d(57)\n",
        "    self.drop10 = nn.Dropout(0)\n",
        "\n",
        "    self.conv11 = nn.Conv2d(in_channels=57,out_channels=32,kernel_size=3,padding=1)\n",
        "    self.baNorm11 = nn.BatchNorm2d(32)\n",
        "    self.drop11 = nn.Dropout(0)\n",
        "\n",
        "    self.conv12 = nn.Conv2d(in_channels=32,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm12 = nn.BatchNorm2d(57)\n",
        "    self.drop12 = nn.Dropout(0)\n",
        "\n",
        "    self.conv13 = nn.Conv2d(in_channels=57,out_channels=118,kernel_size=3,padding=1)\n",
        "    self.baNorm13 = nn.BatchNorm2d(118)\n",
        "    self.drop13 = nn.Dropout(0)\n",
        "\n",
        "    self.conv14 = nn.Conv2d(in_channels=118,out_channels=48,kernel_size=3,padding=1)\n",
        "    self.baNorm14 = nn.BatchNorm2d(48)\n",
        "    self.drop14 = nn.Dropout(0)\n",
        "    \n",
        "\n",
        "    self.conv15 = nn.Conv2d(in_channels=48,out_channels=27,kernel_size=3,padding=1)\n",
        "    self.baNorm15 = nn.BatchNorm2d(27)\n",
        "    self.drop15 = nn.Dropout(0)\n",
        "\n",
        "    self.fc1 = nn.Linear(1354752, 5)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.drop1(nn.functional.relu(self.baNorm1(self.conv1(x))))\n",
        "    x = self.drop2(nn.functional.relu(self.baNorm2(self.conv2(x))))\n",
        "    x = self.drop3(nn.functional.relu(self.baNorm3(self.conv3(x))))\n",
        "    x = self.drop4(nn.functional.relu(self.baNorm4(self.conv4(x))))\n",
        "    x = self.drop5(nn.functional.relu(self.baNorm5(self.conv5(x))))\n",
        "    x = self.drop6(nn.functional.relu(self.baNorm6(self.conv6(x))))\n",
        "    x = self.drop7(nn.functional.relu(self.baNorm7(self.conv7(x))))\n",
        "    x = self.drop8(nn.functional.relu(self.baNorm8(self.conv8(x))))\n",
        "    x = self.drop9(nn.functional.relu(self.baNorm9(self.conv9(x))))\n",
        "    x = self.drop10(nn.functional.relu(self.baNorm10(self.conv10(x))))\n",
        "    x = self.drop11(nn.functional.relu(self.baNorm11(self.conv11(x))))\n",
        "    x = self.drop12(nn.functional.relu(self.baNorm12(self.conv12(x))))\n",
        "    x = self.drop13(nn.functional.relu(self.baNorm13(self.conv13(x))))\n",
        "    x = self.drop14(nn.functional.relu(self.baNorm14(self.conv14(x))))\n",
        "    x = self.drop15(nn.functional.relu(self.baNorm15(self.conv15(x))))\n",
        "    \n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVUWeyMExTK5"
      },
      "source": [
        "### Optuna model suggestion number 2 with skip connections and pooling layers\n",
        "\n",
        "class optuna_res_2_skip_pool(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"CNN Builder.\"\"\"\n",
        "    super(optuna_res_2_skip_pool, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm1 = nn.BatchNorm2d(50)\n",
        "    self.drop1 = nn.Dropout(0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=50,out_channels=76,kernel_size=3,padding=1)\n",
        "    self.baNorm2 = nn.BatchNorm2d(76)\n",
        "    self.drop2 = nn.Dropout(0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=76,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm3 = nn.BatchNorm2d(50)\n",
        "    self.drop3 = nn.Dropout(0)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels=50,out_channels=44,kernel_size=3,padding=1)\n",
        "    self.baNorm4 = nn.BatchNorm2d(44)\n",
        "    self.drop4 = nn.Dropout(0)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels=44,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm5 = nn.BatchNorm2d(50)\n",
        "    self.drop5 = nn.Dropout(0)\n",
        "    self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv6 = nn.Conv2d(in_channels=50,out_channels=120,kernel_size=3,padding=1)\n",
        "    self.baNorm6 = nn.BatchNorm2d(120)\n",
        "    self.drop6 = nn.Dropout(0)\n",
        "\n",
        "    self.conv7 = nn.Conv2d(in_channels=120,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm7 = nn.BatchNorm2d(50)\n",
        "    self.drop7 = nn.Dropout(0)\n",
        "    self.pool7 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv8 = nn.Conv2d(in_channels=50,out_channels=104,kernel_size=3,padding=1)\n",
        "    self.baNorm8 = nn.BatchNorm2d(104)\n",
        "    self.drop8 = nn.Dropout(0)\n",
        "\n",
        "    self.conv9 = nn.Conv2d(in_channels=104,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm9 = nn.BatchNorm2d(50)\n",
        "    self.drop9 = nn.Dropout(0)\n",
        "    self.pool9 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv10 = nn.Conv2d(in_channels=50,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm10 = nn.BatchNorm2d(57)\n",
        "    self.drop10 = nn.Dropout(0)\n",
        "\n",
        "    self.conv11 = nn.Conv2d(in_channels=57,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm11 = nn.BatchNorm2d(50)\n",
        "    self.drop11 = nn.Dropout(0)\n",
        "    self.pool11 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv12 = nn.Conv2d(in_channels=50,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm12 = nn.BatchNorm2d(57)\n",
        "    self.drop12 = nn.Dropout(0)\n",
        "\n",
        "    self.conv13 = nn.Conv2d(in_channels=57,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm13 = nn.BatchNorm2d(50)\n",
        "    self.drop13 = nn.Dropout(0)\n",
        "    self.pool13 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv14 = nn.Conv2d(in_channels=50,out_channels=48,kernel_size=3,padding=1)\n",
        "    self.baNorm14 = nn.BatchNorm2d(48)\n",
        "    self.drop14 = nn.Dropout(0)\n",
        "    \n",
        "\n",
        "    self.conv15 = nn.Conv2d(in_channels=48,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm15 = nn.BatchNorm2d(50)\n",
        "    self.drop15 = nn.Dropout(0)\n",
        "    self.pool15 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(50, 5)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.drop1(nn.functional.relu(self.baNorm1(self.conv1(x))))\n",
        "    temp = x\n",
        "    x = self.drop2(nn.functional.relu(self.baNorm2(self.conv2(x))))\n",
        "    x = self.baNorm3(self.conv3(x))\n",
        "    x+=temp\n",
        "    x = self.drop3(self.pool3(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x\n",
        "    x = self.drop4(nn.functional.relu(self.baNorm4(self.conv4(x))))\n",
        "    x = self.baNorm5(self.conv5(x))\n",
        "    x+=temp\n",
        "    x = self.drop5(self.pool5(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x\n",
        "    x = self.drop6(nn.functional.relu(self.baNorm6(self.conv6(x))))\n",
        "    x = self.baNorm7(self.conv7(x))\n",
        "    x+=temp\n",
        "    x = self.drop7(self.pool7(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x\n",
        "    x = self.drop8(nn.functional.relu(self.baNorm8(self.conv8(x))))\n",
        "    x = self.baNorm9(self.conv9(x))\n",
        "    x+=temp\n",
        "    x = self.drop9(self.pool9(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x    \n",
        "    x = self.drop10(nn.functional.relu(self.baNorm10(self.conv10(x))))\n",
        "    x = self.baNorm11(self.conv11(x))\n",
        "    x+=temp\n",
        "    x = self.drop11(self.pool11(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x   \n",
        "    x = self.drop12(nn.functional.relu(self.baNorm12(self.conv12(x))))\n",
        "    x = self.baNorm13(self.conv13(x))\n",
        "    x+=temp\n",
        "    x = self.drop13(self.pool13(nn.functional.relu(x)))\n",
        "    \n",
        "    temp = x   \n",
        "    x = self.drop14(nn.functional.relu(self.baNorm14(self.conv14(x))))\n",
        "    x = self.baNorm15(self.conv15(x))\n",
        "    x+=temp\n",
        "    x = self.drop15(self.pool15(nn.functional.relu(x)))\n",
        "\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIGBC_x1x8TY"
      },
      "source": [
        "### Optuna model suggestion number 2 with stchastic depth and pooling layers.\n",
        "\n",
        "class optuna_res_2_skip_pool_st_depth(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"CNN Builder.\"\"\"\n",
        "    super(optuna_res_2_skip_pool_st_depth, self).__init__()\n",
        "    #the network\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm1 = nn.BatchNorm2d(50)\n",
        "    self.drop1 = nn.Dropout(0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=50,out_channels=76,kernel_size=3,padding=1)\n",
        "    self.baNorm2 = nn.BatchNorm2d(76)\n",
        "    self.drop2 = nn.Dropout(0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=76,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm3 = nn.BatchNorm2d(50)\n",
        "    self.drop3 = nn.Dropout(0)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels=50,out_channels=44,kernel_size=3,padding=1)\n",
        "    self.baNorm4 = nn.BatchNorm2d(44)\n",
        "    self.drop4 = nn.Dropout(0)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels=44,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm5 = nn.BatchNorm2d(50)\n",
        "    self.drop5 = nn.Dropout(0)\n",
        "    self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv6 = nn.Conv2d(in_channels=50,out_channels=120,kernel_size=3,padding=1)\n",
        "    self.baNorm6 = nn.BatchNorm2d(120)\n",
        "    self.drop6 = nn.Dropout(0)\n",
        "\n",
        "    self.conv7 = nn.Conv2d(in_channels=120,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm7 = nn.BatchNorm2d(50)\n",
        "    self.drop7 = nn.Dropout(0)\n",
        "    self.pool7 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv8 = nn.Conv2d(in_channels=50,out_channels=104,kernel_size=3,padding=1)\n",
        "    self.baNorm8 = nn.BatchNorm2d(104)\n",
        "    self.drop8 = nn.Dropout(0)\n",
        "\n",
        "    self.conv9 = nn.Conv2d(in_channels=104,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm9 = nn.BatchNorm2d(50)\n",
        "    self.drop9 = nn.Dropout(0)\n",
        "    self.pool9 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv10 = nn.Conv2d(in_channels=50,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm10 = nn.BatchNorm2d(57)\n",
        "    self.drop10 = nn.Dropout(0)\n",
        "\n",
        "    self.conv11 = nn.Conv2d(in_channels=57,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm11 = nn.BatchNorm2d(50)\n",
        "    self.drop11 = nn.Dropout(0)\n",
        "    self.pool11 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv12 = nn.Conv2d(in_channels=50,out_channels=57,kernel_size=3,padding=1)\n",
        "    self.baNorm12 = nn.BatchNorm2d(57)\n",
        "    self.drop12 = nn.Dropout(0)\n",
        "\n",
        "    self.conv13 = nn.Conv2d(in_channels=57,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm13 = nn.BatchNorm2d(50)\n",
        "    self.drop13 = nn.Dropout(0)\n",
        "    self.pool13 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv14 = nn.Conv2d(in_channels=50,out_channels=48,kernel_size=3,padding=1)\n",
        "    self.baNorm14 = nn.BatchNorm2d(48)\n",
        "    self.drop14 = nn.Dropout(0)\n",
        "    \n",
        "\n",
        "    self.conv15 = nn.Conv2d(in_channels=48,out_channels=50,kernel_size=3,padding=1)\n",
        "    self.baNorm15 = nn.BatchNorm2d(50)\n",
        "    self.drop15 = nn.Dropout(0)\n",
        "    self.pool15 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(50, 5)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    \n",
        "    x = (self.drop1(nn.functional.relu(self.baNorm1(self.conv1(x))))).to(device)\n",
        "    temp = x.to(device)\n",
        "    rand_pass = random()\n",
        "    if rand_pass > 0.1:\n",
        "      x = self.drop2(nn.functional.relu(self.baNorm2(self.conv2(x))))\n",
        "      x = self.baNorm3(self.conv3(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop3(self.pool3(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x.to(device)\n",
        "    rand_pass = random()\n",
        "    if rand_pass > 0.2:\n",
        "      x = self.drop4(nn.functional.relu(self.baNorm4(self.conv4(x))))\n",
        "      x = self.baNorm5(self.conv5(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop5(self.pool5(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x.to(device)\n",
        "    if rand_pass > 0.3:\n",
        "      x = self.drop6(nn.functional.relu(self.baNorm6(self.conv6(x))))\n",
        "      x = self.baNorm7(self.conv7(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop7(self.pool7(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x\n",
        "    if rand_pass > 0.4:\n",
        "      x = self.drop8(nn.functional.relu(self.baNorm8(self.conv8(x))))\n",
        "      x = self.baNorm9(self.conv9(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop9(self.pool9(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x    \n",
        "    if rand_pass > 0.5:\n",
        "      x = self.drop10(nn.functional.relu(self.baNorm10(self.conv10(x))))\n",
        "      x = self.baNorm11(self.conv11(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop11(self.pool11(nn.functional.relu(x)))\n",
        "\n",
        "    temp = x \n",
        "    if rand_pass > 0.6:  \n",
        "      x = self.drop12(nn.functional.relu(self.baNorm12(self.conv12(x))))\n",
        "      x = self.baNorm13(self.conv13(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop13(self.pool13(nn.functional.relu(x)))\n",
        "    \n",
        "    temp = x  \n",
        "    if rand_pass > 0.7:   \n",
        "      x = self.drop14(nn.functional.relu(self.baNorm14(self.conv14(x))))\n",
        "      x = self.baNorm15(self.conv15(x))\n",
        "    else:\n",
        "      x = (torch.zeros(x.shape)).to(device)\n",
        "    x+=temp.to(device)\n",
        "    x = self.drop15(self.pool15(nn.functional.relu(x)))  \n",
        "\n",
        "    #print(x.shape)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjbIJugsyz1I"
      },
      "source": [
        "### For applying transfer learning using Resnet-18 use this section\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting=False):\n",
        "  if feature_extracting:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    else:\n",
        "      for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        " # Initialize these variables which will be set in this if statement. Each of these\n",
        " # variables is model specific.\n",
        "  model_ft = None\n",
        "  input_size = 0 # image size, e.g. (3, 224, 224)\n",
        "  if model_name == \"resnet\":\n",
        "    \"\"\" Resnet18\"\"\"\n",
        "    model_ft = torchvision.models.resnet18(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 5) # replace the last FC layer\n",
        "    input_size = 224\n",
        "  else:\n",
        "    raise NotImplementedError\n",
        "  return model_ft, input_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1yaS5cf2a58"
      },
      "source": [
        "############### END OF MODELS ####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y2ZNY_n8RyY"
      },
      "source": [
        "# function to calcualte accuracy of the model\n",
        "def calculate_accuracy(my_model, dataloader, device):\n",
        "    my_model.eval() # put in evaluation mode\n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    confusion_matrix = np.zeros([5,5], int)\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = my_model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_images += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            for i, l in enumerate(labels):\n",
        "                confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "    model_accuracy = total_correct / total_images * 100\n",
        "    return model_accuracy, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUX9Owif2U3a"
      },
      "source": [
        "######## Model setup sections ##########\n",
        "###choose only one\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_jyyorC2DZ4"
      },
      "source": [
        "##### if you choose resnet-18 run only this section\n",
        "\n",
        "lr = 0.0005\n",
        "epochs = 30\n",
        "\n",
        "#model configuration \n",
        "model, input = initialize_model(model_name=\"resnet\", num_classes=5, feature_extract=False, use_pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "#weighted classes corresponding to class percentage from total train-set\n",
        "weights = torch.tensor([12.105,6.011,5.514,1,5.106]).to(device)\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()#weight = weights) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)#,weight_decay=0.000001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode='max',factor=0.5,patience=2,verbose = True,threshold_mode='abs',threshold=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W0ZKxEa5VCx"
      },
      "source": [
        "###if you didn‚Äôt choose Resnet18 run only this section. \n",
        "###NOTE : Change the name of the model to the one you chose\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 30\n",
        "#seed(1)\n",
        "#weighted classes corresponding to class percentage from total train-set\n",
        "weights = torch.tensor([12.105,6.011,5.514,1,5.106]).to(device)\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()#weight = weights)\n",
        "\n",
        "### change model name here###\n",
        "model = optuna_res_2_skip_pool_st_depth().to(device)\n",
        "\n",
        "# optimizer - SGD, Adam, RMSProp...\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)#,weight_decay=0.000001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode='max',factor=0.2,patience=2,verbose = True,threshold_mode='abs',threshold=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbp1imj18TUv"
      },
      "source": [
        "######## end of model setup sections ##########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky5_fVrh6BHu"
      },
      "source": [
        "# training loop\n",
        "\n",
        "loss_memory = []\n",
        "epoch_accucary_max=0\n",
        "\n",
        "### enter the path you desire the best model to be saved in.\n",
        "save_path = '/content/drive/MyDrive/YOUR_MODEL_SAVING_PATH'\n",
        "save_path= os.path.join(save_path,('model_weights.pth'))\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()  # put in training mode\n",
        "    running_loss = 0.0\n",
        "    for i,data in enumerate(train_loader):\n",
        "      if(i%50 == 0):\n",
        "        print('epoch :',epoch, 'batch :',i)\n",
        "      \n",
        "      # get the inputs\n",
        "      inputs, labels = data\n",
        "      \n",
        "      # send them to device\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(inputs)  # forward pass\n",
        "      loss = criterion(outputs, labels)  # calculate the loss\n",
        "      optimizer.zero_grad()  # zero the parameter gradients\n",
        "      loss.backward()  # backpropagation\n",
        "      optimizer.step()  # update parameters\n",
        "\n",
        "      running_loss += loss.data.item()\n",
        "\n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss /= len(train_loader)\n",
        "\n",
        "    valid_accuracy, _ = calculate_accuracy(model, valid_loader, device)\n",
        "    train_accuracy, _ = calculate_accuracy(model, train_loader, device)\n",
        "    loss_memory.append(running_loss)\n",
        "    \n",
        "    ###the following comment let you change the LR every X epochs. you can use it instead of the scheduler.\n",
        "    \"\"\"\n",
        "    if ((epoch+1)%5 == 0):\n",
        "      lr = lr*0.5\n",
        "      optimizer.param_groups[0]['lr'] = lr\n",
        "    \"\"\"\n",
        "    print('epoch :',epoch,\"|loss :\", running_loss,\"|train_acc:\",train_accuracy,\"|val_acc :\",valid_accuracy,\"lr :\",optimizer.param_groups[0]['lr'])\n",
        "    scheduler.step(valid_accuracy)\n",
        "\n",
        "    ### saving best model based on validation accuracy\n",
        "    if epoch_accucary_max <= valid_accuracy:\n",
        "      epoch_accucary_max = valid_accuracy\n",
        "      state = {\n",
        "        'net': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "      }\n",
        "      print(\"valid accuracy improved to : \",epoch_accucary_max)\n",
        "      torch.save(state,save_path)\n",
        "\n",
        "    \n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpVqxs9578dZ"
      },
      "source": [
        "### model evaluation \n",
        "\n",
        "def plot_confusion_matrix(confusion_matrix):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    classes = ('0', '1', '2', '3', '4')\n",
        "    #plt.yticks(range(5), classes)\n",
        "    heatmap = sns.heatmap(confusion_matrix, annot=True, cmap='cubehelix', yticklabels=classes, xticklabels=classes)\n",
        "    heatmap.set_title('Confusion Matrix', fontdict={'fontsize':18}, pad=16)\n",
        "    plt.ylabel('Actual Category')\n",
        "    plt.xlabel('Predicted Category')\n",
        "    plt.show()\n",
        "\n",
        "# load model, calculate accuracy and confusion matrix\n",
        "\n",
        "model = model.to(device)\n",
        "state = torch.load(save_path, map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "test_accuracy, confusion_matrix = calculate_accuracy(model, test_loader, device)\n",
        "print(\"test accuracy: {:.3f}%\".format(test_accuracy))\n",
        "\n",
        "# plot confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wshqbvcV87f_"
      },
      "source": [
        "########### OPTUNA #############\n",
        "###the following sections are for operating Optuna only.\n",
        "### you can find more imformation about Optuna here : \"https://optuna.org/\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDo-ToS9-VQz"
      },
      "source": [
        "def define_model(trial):\n",
        "  # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 7, 20) # number of layers will be between 1 and 3\n",
        "  first_conv_maps = trial.suggest_int(\"first_conv_maps\",16,256)\n",
        "  layers = []\n",
        "  #in_channels = 224 * 224\n",
        "  layers.append(nn.Conv2d(in_channels=3,out_channels=first_conv_maps,kernel_size=3,padding = 1))\n",
        "  layers.append(nn.BatchNorm2d(first_conv_maps))\n",
        "  layers.append(nn.ReLU())\n",
        "  drop_layer1 = trial.suggest_float(\"drop_layer1\",0.1,0.5)\n",
        "  layers.append(nn.Dropout(drop_layer1))\n",
        "  in_channels = first_conv_maps\n",
        "  for i in range(n_layers):\n",
        "    out_channels = trial.suggest_int(\"n_units_l{}\".format(i+2), 16, 128) # number of units will be between 4 and 128\n",
        "    layers.append(nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding = 1))   #nn.Linear(in_features, out_features))\n",
        "    layers.append(nn.BatchNorm2d(out_channels))\n",
        "    layers.append(nn.ReLU())\n",
        "    p = trial.suggest_float(\"dropout_l{}\".format(i+2), 0.1, 0.5) # dropout rate will be between 0.2 and 0.5\n",
        "    layers.append(nn.Dropout(p))\n",
        "    in_channels = out_channels\n",
        "\n",
        "  last_conv_channels = trial.suggest_int(\"last_conv_maps\",4,64)\n",
        "  layers.append(nn.Conv2d(in_channels=in_channels,out_channels=last_conv_channels,kernel_size=3,padding = 1))\n",
        "  layers.append(nn.BatchNorm2d(last_conv_channels))\n",
        "  layers.append(nn.ReLU())\n",
        "  drop_layer_last = trial.suggest_float(\"drop_layer_last\",0.1,0.5)\n",
        "  layers.append(nn.Dropout(drop_layer_last))\n",
        "  layers.append(nn.Flatten(start_dim=1, end_dim=-1))\n",
        "  layers.append(nn.Linear(last_conv_channels*224*224, 5))\n",
        "  #layers.append(nn.LogSoftmax(dim=1))\n",
        "  return nn.Sequential(*layers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVQXFvGy-WRg"
      },
      "source": [
        "batch_size = 8\n",
        "classes = 5\n",
        "epochs = 15\n",
        "log_interval = 10\n",
        "n_train_examples = batch_size * 50\n",
        "n_valid_examples = batch_size * 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EzdR3M5-eIe"
      },
      "source": [
        "def objective(trial):\n",
        "  # Generate the model.\n",
        "  batch_size = 8\n",
        "  classes = 5\n",
        "  epochs = 15\n",
        "  log_interval = 10\n",
        "  n_train_examples = batch_size * 50\n",
        "  n_valid_examples = batch_size * 20\n",
        "  \n",
        "  \n",
        "  image_path = \"/content/dataset\"\n",
        "  train_csv = \"/content/drive/TRAIN_CSV_PATH/dataset-train.csv\"\n",
        "  test_csv_path = \"/content/drive/TRAIN_CSV_PATH/dataset-test.csv\"\n",
        "  basic_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "  train_dataset = Cassava_Dataset(image_path,train_csv,basic_transform)\n",
        "  valid_set = Cassava_Dataset(image_path,test_csv_path,test_transform)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_set,batch_size=batch_size,shuffle=True)\n",
        "  \n",
        "  weight_class_0 = trial.suggest_float(\"weight_class0\", 0.5, 5)\n",
        "  weight_class_1 = trial.suggest_float(\"weight_class1\", 0.5, 5)\n",
        "  weight_class_2 = trial.suggest_float(\"weight_class2\", 0.5, 5)\n",
        "  weight_class_3 = trial.suggest_float(\"weight_class3\", 0.5, 5)\n",
        "  weight_class_4 = trial.suggest_float(\"weight_class4\", 0.5, 5)\n",
        "  weights = torch.tensor([weight_class_0,weight_class_1,weight_class_2,weight_class_3,weight_class_4]).to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "  \n",
        "\n",
        "  model = define_model(trial).to(device)\n",
        "  # Generate the optimizers.\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) # log=True, will use log scale to interplolate between lr\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
        "\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  # alternative version\n",
        "  # optimizer = trial.suggest_categorical(\"optimizer\", [optim.Adam, optim.RMSprop, optim.SGD])\n",
        "  # Get the MNIST dataset.\n",
        "  train_loader, valid_loader = train_loader,valid_loader\n",
        "  # Training of the model.\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      # Limiting training data for faster epochs.\n",
        "      if batch_idx * batch_size >= n_train_examples:\n",
        "        break\n",
        "      data, target = data.data.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        " # Validation of the model.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "      # Limiting validation data.\n",
        "        if batch_idx * batch_size >= n_valid_examples:\n",
        "          break\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        # Get the index of the max log-probability.\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = correct / min(len(valid_loader.dataset), n_valid_examples)\n",
        "    # report back to Optuna how far it is (epoch-wise) into the trial and how well it is doing (accuracy)\n",
        "    trial.report(accuracy, epoch)\n",
        "    # then, Optuna can decide if the trial should be pruned\n",
        "    # Handle pruning based on the intermediate value.\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.TrialPruned()\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8tG32mpBj6J"
      },
      "source": [
        "sampler = optuna.samplers.TPESampler()\n",
        "study = optuna.create_study(study_name=\"cassava-cnn\", direction=\"maximize\", sampler=sampler)\n",
        "\n",
        "study.optimize(objective, n_trials=500)#, timeout=600)trial,train_loader=train_loader,valid_loader=valid_loader\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\" Number of finished trials: \", len(study.trials))\n",
        "print(\" Number of pruned trials: \", len(pruned_trials))\n",
        "print(\" Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\" Value: \", trial.value)\n",
        "\n",
        "print(\" Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\" {}: {}\".format(key, value))\n",
        "\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}